# ‚õΩ Carburant ETL ‚Äì Pipeline de traitement des prix des carburants en France

Un pipeline **ETL local modulaire**, d√©velopp√© en Python, orchestr√© avec **Airflow** et stock√© dans **PostgreSQL**, pour extraire, transformer et charger les donn√©es de prix de carburants en France publi√©es par le gouvernement (open data).

---

## üöÄ Objectifs

- Extraire les donn√©es XML compress√©es depuis l‚ÄôAPI publique [roulez-eco.fr](https://donnees.roulez-eco.fr/opendata/instantane)
- D√©compresser, parser et transformer les donn√©es avec pandas
- Charger dans une base PostgreSQL locale
- Orchestrer le tout avec Apache Airflow (Docker)
- Exporter les donn√©es en **CSV**
- Exporter les donn√©es en **Parquet** avec une structure type **Data Lake (bronze)**
- Centraliser les param√®tres dans un fichier `.env`
- Visualiser les donn√©es avec Streamlit

---

## üß∞ Stack technique

- Python 3.12
- Apache Airflow 2.9 (via Docker)
- PostgreSQL 15
- pandas
- psycopg2
- pyarrow
- dotenv
- Docker / docker-compose
- Streamlit

---

## ‚öôÔ∏è Installation et lancement

### 1. Cloner le d√©p√¥t

```bash
git clone https://github.com/<TON-UTILISATEUR>/carburant_etl.git
cd carburant_etl
```

### 2. Cr√©er les dossiers de travail

```bash
mkdir -p airflow/data airflow/logs airflow/plugins
mkdir -p airflow/data/parquet/bronze
```

### 3. Cr√©er le fichier `.env`

```env
DB_HOST=postgres
DB_PORT=5432
DB_NAME=airflow
DB_USER=airflow
DB_PASSWORD=airflow

RAW_DATA_PATH=/opt/airflow/data/PrixCarburants_instantane.xml
CLEAN_DATA_PATH=/opt/airflow/data/clean.csv
PARQUET_BRONZE_DIR=/opt/airflow/data/parquet/bronze
DATA_DIR=/opt/airflow/data
```

### 4. D√©marrer les services avec Docker

```bash
docker-compose up --build
```

### 5. Acc√©der aux interfaces

- **Airflow** : [http://localhost:8080](http://localhost:8080) (`admin` / `admin`)
- **Streamlit** : [http://localhost:8501](http://localhost:8501)

---

## üìä Donn√©es utilis√©es

- Source : [data.gouv.fr ‚Äì prix des carburants](https://www.data.gouv.fr/fr/datasets/prix-des-carburants-en-france-flux-instantane)
- Format : XML compress√© `.zip`
- Champs : nom station, ville, code postal, carburant, prix, date de mise √† jour

---

## üß™ Qualit√© des donn√©es

- Suppression des lignes avec `prix <= 0` ou valeurs manquantes
- Parsing strict des dates et types num√©riques
- Historisation des donn√©es Parquet dans un dossier dat√© (ex: /data/parquet/bronze/2025-08-01_20-45.parquet)
---

## üîÑ DAG Airflow

Le pipeline Airflow est compos√© de 4 t√¢ches :

1. `extract_data` ‚Äì T√©l√©charge et d√©compresse les donn√©es XML
2. `transform_data` ‚Äì Nettoie les donn√©es et les sauvegarde en CSV et Parquet
3. `load_data` ‚Äì Charge les donn√©es dans PostgreSQL (depuis CSV et Parquet)

Planifi√© toutes les **10 minutes** (`*/10 * * * *`).

---

## üë®‚Äçüíª Auteur

**Mohamed Manssour Ghorbel**  
Projet personnel de formation en data engineering  
üì´ [LinkedIn](https://www.linkedin.com/in/mohamed-manssour-ghorbel-a93a8813b/)

---

## üìÑ Licence

Ce projet est sous licence MIT ‚Äì libre d‚Äôutilisation √† des fins p√©dagogiques.
